{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMbJjbvodv0u60+w6McnUIg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52252-ux/NLP/blob/main/8_2_vyshnavi_2252(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corpus"
      ],
      "metadata": {
        "id": "5w_PYIeYKtqV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9j_0Cs4IJcOm"
      },
      "outputs": [],
      "source": [
        "D1 = \"I wake up early every morning\"\n",
        "D2 = \"I brush my teeth and get ready for college\"\n",
        "D3 = \"My mother prepares breakfast for us\"\n",
        "D4 = \"I go to college by bus\"\n",
        "D5 = \"I attend classes and take notes\"\n",
        "D6 = \"I have lunch with my friends\"\n",
        "D7 = \"I return home in the evening\"\n",
        "D8 = \"I complete my assignments at night\"\n",
        "D9 = \"My family watches television together\"\n",
        "D10 = \"I go to bed before 11 pm\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uni Gram Counts"
      ],
      "metadata": {
        "id": "sN9nnxCmK1gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "# Combine the text from D1, D2, D3, D4 ,D5,D6,D7,D8,D9,D10\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"# Tokenize the combined text into words and convert to lowercase\n",
        "words = combined_text.lower().split()\n",
        "\n",
        "# Calculate unigram counts\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "# Print the unigram counts\n",
        "print(\"Unigram Counts:\")\n",
        "for word, count in unigram_counts.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "#Vocabulary size is length of unigrams\n",
        "V=len(unigram_counts)\n",
        "print(\"Vocabulary Size=\",V)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxMNtKQGK5kE",
        "outputId": "ca3100f4-6bda-4710-c724-6f45d19be192"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Counts:\n",
            "i: 8\n",
            "my: 5\n",
            "and: 2\n",
            "for: 2\n",
            "college: 2\n",
            "go: 2\n",
            "to: 2\n",
            "wake: 1\n",
            "up: 1\n",
            "early: 1\n",
            "every: 1\n",
            "morning: 1\n",
            "brush: 1\n",
            "teeth: 1\n",
            "get: 1\n",
            "ready: 1\n",
            "mother: 1\n",
            "prepares: 1\n",
            "breakfast: 1\n",
            "us: 1\n",
            "by: 1\n",
            "bus: 1\n",
            "attend: 1\n",
            "classes: 1\n",
            "take: 1\n",
            "notes: 1\n",
            "have: 1\n",
            "lunch: 1\n",
            "with: 1\n",
            "friends: 1\n",
            "return: 1\n",
            "home: 1\n",
            "in: 1\n",
            "the: 1\n",
            "evening: 1\n",
            "complete: 1\n",
            "assignments: 1\n",
            "at: 1\n",
            "night: 1\n",
            "family: 1\n",
            "watches: 1\n",
            "television: 1\n",
            "together: 1\n",
            "bed: 1\n",
            "before: 1\n",
            "11: 1\n",
            "pm: 1\n",
            "Vocabulary Size= 47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bi-Gram Counts"
      ],
      "metadata": {
        "id": "43NXp6qCLPLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "words = combined_text.lower().split()\n",
        "# Generate bigrams\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "# Print the bigram counts\n",
        "print(\"\\nBigram Counts:\")\n",
        "for bigram, count in bigram_counts.most_common():\n",
        "    print(f\"{bigram[0]} {bigram[1]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjhmCsD4LPr_",
        "outputId": "53022ba4-8344-4225-b1f2-968431e88984"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigram Counts:\n",
            "i go: 2\n",
            "go to: 2\n",
            "i wake: 1\n",
            "wake up: 1\n",
            "up early: 1\n",
            "early every: 1\n",
            "every morning: 1\n",
            "morning i: 1\n",
            "i brush: 1\n",
            "brush my: 1\n",
            "my teeth: 1\n",
            "teeth and: 1\n",
            "and get: 1\n",
            "get ready: 1\n",
            "ready for: 1\n",
            "for college: 1\n",
            "college my: 1\n",
            "my mother: 1\n",
            "mother prepares: 1\n",
            "prepares breakfast: 1\n",
            "breakfast for: 1\n",
            "for us: 1\n",
            "us i: 1\n",
            "to college: 1\n",
            "college by: 1\n",
            "by bus: 1\n",
            "bus i: 1\n",
            "i attend: 1\n",
            "attend classes: 1\n",
            "classes and: 1\n",
            "and take: 1\n",
            "take notes: 1\n",
            "notes i: 1\n",
            "i have: 1\n",
            "have lunch: 1\n",
            "lunch with: 1\n",
            "with my: 1\n",
            "my friends: 1\n",
            "friends i: 1\n",
            "i return: 1\n",
            "return home: 1\n",
            "home in: 1\n",
            "in the: 1\n",
            "the evening: 1\n",
            "evening i: 1\n",
            "i complete: 1\n",
            "complete my: 1\n",
            "my assignments: 1\n",
            "assignments at: 1\n",
            "at night: 1\n",
            "night my: 1\n",
            "my family: 1\n",
            "family watches: 1\n",
            "watches television: 1\n",
            "television together: 1\n",
            "together i: 1\n",
            "to bed: 1\n",
            "bed before: 1\n",
            "before 11: 1\n",
            "11 pm: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tri-Gram Counts\n"
      ],
      "metadata": {
        "id": "pbyhiwrSNauG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "combined_text = f\"{D1} {D2} {D3} {D4} {D5} {D6} {D7} {D8} {D9} {D10}\"\n",
        "words = combined_text.lower().split()\n",
        "# Generate bigrams\n",
        "Trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    Trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "# Calculate bigram counts\n",
        "Trigrams_counts = collections.Counter(Trigrams)\n",
        "# Print the bigram counts\n",
        "print(\"\\nTrigrams Counts:\")\n",
        "for Trigrams, count in Trigrams_counts.most_common():\n",
        "    print(f\"{Trigrams[0]} {Trigrams[1]} {Trigrams[2]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOibKSE2NbSt",
        "outputId": "f62576f0-3cb3-43b9-c9af-c3e32c161382"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trigrams Counts:\n",
            "i go to: 2\n",
            "i wake up: 1\n",
            "wake up early: 1\n",
            "up early every: 1\n",
            "early every morning: 1\n",
            "every morning i: 1\n",
            "morning i brush: 1\n",
            "i brush my: 1\n",
            "brush my teeth: 1\n",
            "my teeth and: 1\n",
            "teeth and get: 1\n",
            "and get ready: 1\n",
            "get ready for: 1\n",
            "ready for college: 1\n",
            "for college my: 1\n",
            "college my mother: 1\n",
            "my mother prepares: 1\n",
            "mother prepares breakfast: 1\n",
            "prepares breakfast for: 1\n",
            "breakfast for us: 1\n",
            "for us i: 1\n",
            "us i go: 1\n",
            "go to college: 1\n",
            "to college by: 1\n",
            "college by bus: 1\n",
            "by bus i: 1\n",
            "bus i attend: 1\n",
            "i attend classes: 1\n",
            "attend classes and: 1\n",
            "classes and take: 1\n",
            "and take notes: 1\n",
            "take notes i: 1\n",
            "notes i have: 1\n",
            "i have lunch: 1\n",
            "have lunch with: 1\n",
            "lunch with my: 1\n",
            "with my friends: 1\n",
            "my friends i: 1\n",
            "friends i return: 1\n",
            "i return home: 1\n",
            "return home in: 1\n",
            "home in the: 1\n",
            "in the evening: 1\n",
            "the evening i: 1\n",
            "evening i complete: 1\n",
            "i complete my: 1\n",
            "complete my assignments: 1\n",
            "my assignments at: 1\n",
            "assignments at night: 1\n",
            "at night my: 1\n",
            "night my family: 1\n",
            "my family watches: 1\n",
            "family watches television: 1\n",
            "watches television together: 1\n",
            "television together i: 1\n",
            "together i go: 1\n",
            "go to bed: 1\n",
            "to bed before: 1\n",
            "bed before 11: 1\n",
            "before 11 pm: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts"
      ],
      "metadata": {
        "id": "nrkmuDmeNxXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = bigram_count / last_word_unigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "    return predicted_word\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "sequence3 = \"brush my\"\n",
        "next_word3 = predict_next_word_bigram(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6fG2w-GNz6D",
        "outputId": "0187b469-76a4-4a03-ad25-bc65c903f5ff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am', predicted next word: 'No bigram found starting with 'am'.'\n",
            "probability of  teeth is  0.2\n",
            "probability of  mother is  0.2\n",
            "probability of  friends is  0.2\n",
            "probability of  assignments is  0.2\n",
            "probability of  family is  0.2\n",
            "Given sequence: 'I did my', predicted next word: 'teeth'\n",
            "probability of  teeth is  0.2\n",
            "probability of  mother is  0.2\n",
            "probability of  friends is  0.2\n",
            "probability of  assignments is  0.2\n",
            "probability of  family is  0.2\n",
            "Given sequence: 'brush my', predicted next word: 'teeth'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Bi-Gram Model"
      ],
      "metadata": {
        "id": "kaaQLQh7OF1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qxtocY4OQoo",
        "outputId": "902edb30-4e6f-46c9-da58-0f53db7ca704"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textup early\n",
            "probability of  every is  1.0\n",
            "Given sequence: 'up early', predicted next word: 'every'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts"
      ],
      "metadata": {
        "id": "TEBjEMPSPBe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = trigram_count / last_two_words_bigram_count\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "    # Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"wake up\"\n",
        "next_word1 = predict_next_word_trigram(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I will \"\n",
        "next_word2 = predict_next_word_trigram(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SosiPMDuPJDZ",
        "outputId": "5fe1e81f-466e-4dc3-a1a2-c54b0cde6d2f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  early is  1.0\n",
            "Given sequence: 'wake up', predicted next word: 'early'\n",
            "Given sequence: 'I will ', predicted next word: 'No trigram found starting with 'i will'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Tri-Gram Model\n"
      ],
      "metadata": {
        "id": "pgwouL9pPt6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7Y78SQMPunv",
        "outputId": "d3379a2f-9e9e-404b-8cf7-cf0815e4cd81"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textfor college\n",
            "probability of  my is  1.0\n",
            "Given sequence: 'for college', predicted next word: 'my'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Laplace Smoothening\n"
      ],
      "metadata": {
        "id": "uEahalhNQA79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_Laplace(word_sequence, bigram_counts, unigram_counts):\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+1) / (last_word_unigram_count+V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I am\"\n",
        "next_word1 = predict_next_word_bigram_Laplace(sequence1, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I did my\"\n",
        "next_word2 = predict_next_word_bigram_Laplace(sequence2, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"go to\"\n",
        "next_word3 = predict_next_word_bigram_Laplace(sequence3, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_Laplace(sequence4, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lORrs81tQBjf",
        "outputId": "b01166d9-0ebb-4c11-b0fb-d8acd6f8e196"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I am', predicted next word: 'No bigram found starting with 'am'.'\n",
            "probability of teeth is  0.038461538461538464\n",
            "probability of mother is  0.038461538461538464\n",
            "probability of friends is  0.038461538461538464\n",
            "probability of assignments is  0.038461538461538464\n",
            "probability of family is  0.038461538461538464\n",
            "Given sequence: 'I did my', predicted next word: 'teeth'\n",
            "probability of college is  0.04081632653061224\n",
            "probability of bed is  0.04081632653061224\n",
            "Given sequence: 'go to', predicted next word: 'college'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "iKDT2wvNQk2s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_Laplace(ip_text, bigram_counts, unigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8S_1zTqQlmO",
        "outputId": "efbb013e-548b-4984-b25d-e11b4ba94a8e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti go\n",
            "probability of to is  0.061224489795918366\n",
            "Given sequence: 'i go', predicted next word: 'to'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts based on laplace smoothening"
      ],
      "metadata": {
        "id": "7qB0t_3BQxN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_Laplace(word_sequence, Trigrams_counts, bigram_counts):\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+1) / (last_two_words_bigram_count+V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"wake up\"\n",
        "next_word1 = predict_next_word_trigram_Laplace(sequence1, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"I go\"\n",
        "next_word2 = predict_next_word_trigram_Laplace(sequence2, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgQdEOH1QzWW",
        "outputId": "cb7e3825-6961-4238-c03d-965fa165117e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  early is  0.041666666666666664\n",
            "Given sequence: 'wake up', predicted next word: 'early'\n",
            "probability of  to is  0.061224489795918366\n",
            "Given sequence: 'I go', predicted next word: 'to'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Laplace Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "kiBnpT1YRaVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_Laplace(ip_text, Trigrams_counts, bigram_counts)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsSaOT5_Ra3n",
        "outputId": "85539dd5-b384-4984-fabb-4b42b5af854d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textgo to\n",
            "probability of  college is  0.04081632653061224\n",
            "probability of  bed is  0.04081632653061224\n",
            "Given sequence: 'go to', predicted next word: 'college'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "oPZPttotRgOe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_bigram_K(word_sequence, bigram_counts, unigram_counts, K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence and get the last word\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "    last_word = words_in_sequence[-1]\n",
        "\n",
        "    # Find potential next words based on bigrams starting with last_word\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2), count in bigram_counts.items():\n",
        "        if w1 == last_word:\n",
        "            potential_next_words[w2] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No bigram found starting with '{last_word}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w2 | w1) = Count(w1, w2) / Count(w1)\n",
        "    last_word_unigram_count = unigram_counts.get(last_word, 0)\n",
        "    if last_word_unigram_count == 0:\n",
        "        return f\"'{last_word}' not found in unigram counts. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, bigram_count in potential_next_words.items():\n",
        "        probability = (bigram_count+K) / (last_word_unigram_count+K*V)\n",
        "        print(\"probability of \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts and unigram_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \"I will\"\n",
        "next_word1 = predict_next_word_bigram_K(sequence1, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"i go\"\n",
        "next_word2 = predict_next_word_bigram_K(sequence2, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")\n",
        "\n",
        "sequence3 = \"do my\"\n",
        "next_word3 = predict_next_word_bigram_K(sequence3, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence3}', predicted next word: '{next_word3}'\")\n",
        "\n",
        "sequence4 = \"nonexistent word\"\n",
        "next_word4 = predict_next_word_bigram_K(sequence4, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence4}', predicted next word: '{next_word4}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-scQx-NRjfJ",
        "outputId": "bcb7c71d-cb70-4bc1-b70a-7d25129d43fa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given sequence: 'I will', predicted next word: 'No bigram found starting with 'will'.'\n",
            "probability of to is  0.09803921568627451\n",
            "Given sequence: 'i go', predicted next word: 'to'\n",
            "probability of teeth is  0.05263157894736842\n",
            "probability of mother is  0.05263157894736842\n",
            "probability of friends is  0.05263157894736842\n",
            "probability of assignments is  0.05263157894736842\n",
            "probability of family is  0.05263157894736842\n",
            "Given sequence: 'do my', predicted next word: 'teeth'\n",
            "Given sequence: 'nonexistent word', predicted next word: 'No bigram found starting with 'word'.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Bi-Gram Model"
      ],
      "metadata": {
        "id": "e_mlwUKwR4XK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_bigram_K(ip_text, bigram_counts, unigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyc2_98HR49W",
        "outputId": "27893805-14ed-4950-cce9-131d345767e8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textin the\n",
            "probability of evening is  0.061224489795918366\n",
            "Given sequence: 'in the', predicted next word: 'evening'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram Counts with Add - K Smoothening"
      ],
      "metadata": {
        "id": "X63WQBqbSPqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word_trigram_K(word_sequence, Trigrams_counts, bigram_counts,K): #K=0.5-0.01\n",
        "    # Tokenize the input sequence\n",
        "    words_in_sequence = word_sequence.lower().split()\n",
        "    if not words_in_sequence:\n",
        "        return \"Please provide a word sequence.\"\n",
        "\n",
        "    # Ensure at least two words for trigram prediction\n",
        "    if len(words_in_sequence) < 2:\n",
        "        return \"Sequence must contain at least two words for trigram prediction.\"\n",
        "\n",
        "    # Get the last two words as a tuple\n",
        "    last_two_words_tuple = tuple(words_in_sequence[-2:])\n",
        "\n",
        "    # Find potential next words based on trigrams starting with the last two words\n",
        "    potential_next_words = {}\n",
        "    for (w1, w2, w3), count in Trigrams_counts.items():\n",
        "        if (w1, w2) == last_two_words_tuple:\n",
        "            potential_next_words[w3] = count\n",
        "\n",
        "    if not potential_next_words:\n",
        "        return f\"No trigram found starting with '{' '.join(last_two_words_tuple)}'.\"\n",
        "\n",
        "    # Calculate probabilities for potential next words\n",
        "    # P(w3 | w1,w2) = Count(w1, w2, w3) / Count(w1, w2)\n",
        "    # The denominator should be the count of the bigram (w1, w2)\n",
        "    last_two_words_bigram_count = bigram_counts.get(last_two_words_tuple, 0)\n",
        "    if last_two_words_bigram_count == 0:\n",
        "        return f\"'{' '.join(last_two_words_tuple)}' not found as a bigram. Cannot predict next word.\"\n",
        "\n",
        "    predicted_word = None\n",
        "    max_probability = -1\n",
        "\n",
        "    for next_word, trigram_count in potential_next_words.items():\n",
        "        probability = (trigram_count+K) / (last_two_words_bigram_count+K*V)\n",
        "        print(\"probability of  \" f'{next_word}' \" is \", probability)\n",
        "        if probability > max_probability:\n",
        "            max_probability = probability\n",
        "            predicted_word = next_word\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Example usage:\n",
        "# Ensure bigram_counts, unigram_counts, and Trigrams_counts are defined from previous cells\n",
        "# (They are present in the kernel state.)\n",
        "\n",
        "# Try with a word sequence\n",
        "sequence1 = \" my mother\"\n",
        "next_word1 = predict_next_word_trigram_K(sequence1, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence1}', predicted next word: '{next_word1}'\")\n",
        "\n",
        "sequence2 = \"go to\"\n",
        "next_word2 = predict_next_word_trigram_K(sequence2, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{sequence2}', predicted next word: '{next_word2}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sngg5aPeSQOx",
        "outputId": "39390b7c-cb9d-4cc1-c813-fcd7a4ee802e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "probability of  prepares is  0.061224489795918366\n",
            "Given sequence: ' my mother', predicted next word: 'prepares'\n",
            "probability of  college is  0.058823529411764705\n",
            "probability of  bed is  0.058823529411764705\n",
            "Given sequence: 'go to', predicted next word: 'college'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of Add-K Smoothening based Tri-Gram Model"
      ],
      "metadata": {
        "id": "ycI6aYIDSiFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ip_text=input(\"enter text\")\n",
        "next_word1 = predict_next_word_trigram_K(ip_text, Trigrams_counts, bigram_counts,0.5)\n",
        "print(f\"Given sequence: '{ip_text}', predicted next word: '{next_word1}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUI0nwObSinu",
        "outputId": "0c2205ad-9fe5-48f4-82af-36f50fa48f9f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter textmy mother\n",
            "probability of  prepares is  0.061224489795918366\n",
            "Given sequence: 'my mother', predicted next word: 'prepares'\n"
          ]
        }
      ]
    }
  ]
}